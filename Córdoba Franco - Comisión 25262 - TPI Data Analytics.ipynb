#Importar Pandas y Numpy
import pandas as pd
import numpy as np

#Montar la unidad
from google.colab import drive
drive.mount('/content/drive')

#Verificar que los archivos csv est√©n en la carpeta datasets
import os
os.listdir("/content/drive/MyDrive/datasets")


#Definir las rutas de los datasets
ruta_ventas = "/content/drive/MyDrive/datasets/ventas.csv"
ruta_clientes = "/content/drive/MyDrive/datasets/clientes.csv"
ruta_marketing = "/content/drive/MyDrive/datasets/marketing.csv"

#Cargar los CSV como dataframes
df_ventas = pd.read_csv(ruta_ventas)
df_clientes = pd.read_csv(ruta_clientes)
df_marketing = pd.read_csv(ruta_marketing)

#Ver las primeras 5 filas de cada dataframe
display(df_ventas.head(3))
display(df_clientes.head(3))
display(df_marketing.head(3))

#Exploratory data analysis (EDA)

#Definir funci√≥n eda
def eda(df, nombre):
    print(f"----- {nombre} -----")

    #Mostrar el tama√±o del dataframe (filas, columnas)
    print("shape:", df.shape)

    #Listar los nombres de las columnas
    print("columnas:", list(df.columns))

    #Mostrar e imprimir el tipo de dato de cada columna (num√©rico, texto, fecha, etc.)
    print("dtypes:")
    print(df.dtypes)

    #Indicar cu√°ntos valores vac√≠os hay por columna
    print("\nNulos por columna:")
    print(df.isna().sum())

    #Mostrar las primeras 5 filas para tener una vista r√°pida de los datos
    print("\nPrimeras filas:")
    display(df.head(5))

    #Dar estad√≠sticas b√°sicas (promedio, desv√≠o, m√≠nimo, m√°ximo, etc.) solo de las columnas num√©ricas.
    print("\nDescribe (num√©rico):")
    display(df.describe(include='number'))
    print("-"*100)



#Ejecutar la funci√≥n para dataframe ventas
eda(df_ventas, "Ventas 2024 (inicial)")

#Ejecutar la funci√≥n para dataframe clientes
eda(df_clientes, "Clientes 2024 (inicial)")

#Ejecutar la funci√≥n para dataframe marketing
eda(df_marketing, "Marketing 2024 (inicial)")

#Calidad de datos: identificar valores nulos y duplicados


def calidad(df, nombre, clave=None):

#Identificar qu√© conjunto de datos se est√° analizando.
  print(f"### {nombre}")

#Mostrar cu√°ntos valores vac√≠os tiene cada columna.
  display(df.isna().sum().to_frame("nulos"))

#Detectar filas duplicadas id√©nticas (todas las columnas id√©nticas)
  dup_rows = df.duplicated(keep=False).sum()
  print("Filas duplicadas (exactas):", dup_rows)

#Revisar si hay valores duplicados en columna indicada y contarlos
  if clave and clave in df.columns:
      dup_key = df[clave].duplicated(keep=False).sum()
      print(f"Duplicados por clave '{clave}':", dup_key)

#Mostrar los valores m√°s repetidos. Si existen valores duplicados, mostrar los 10 m√°s repetidos en la columna clave

  if clave and clave in df.columns:
    dup_key = df[clave].duplicated(keep=False).sum()
    print(f"Duplicados por clave '{clave}':", dup_key)

    if dup_key > 0:
        duplicados_ordenados = (
            df[df[clave].duplicated(keep=False)][clave]
            .value_counts()
            .sort_values(ascending=False)
        )

        print("\nüîÅ Top valores duplicados m√°s frecuentes:")
        display(duplicados_ordenados.head(10))
    else:
        print(f"No se encontraron duplicados en la clave '{clave}'.")
  else:
    # Si la clave no fue pasada o no existe en el DataFrame
    if clave:
        print(f"La clave '{clave}' no existe en el DataFrame.")
    else:
        print("No se indic√≥ una clave para analizar duplicados por columna.")

#Ejecutar c√≥digo de calidad para dataframe ventas con columna "id_venta"
calidad(df_ventas, "Ventas", clave="id_venta")

#Ejecutar c√≥digo de calidad para dataframe clientes con columna "id_cliente"
calidad(df_clientes, "Clientes", clave="id_cliente")

#Ejecutar c√≥digo de calidad para dataframe marketing con columna "id_campanha"
calidad(df_marketing, "M√°rketing", clave="id_campanha")

#Limpieza del dataset

#Crear copia de los dataframes para no sobreescribir los archivos originales
ventas_limpio = df_ventas.copy()
clientes_limpio = df_clientes.copy()
marketing_limpio = df_marketing.copy()

#Eliminar filas completamente duplicadas

ventas_limpio = ventas_limpio.drop_duplicates()
clientes_limpio = clientes_limpio.drop_duplicates()
marketing_limpio = marketing_limpio.drop_duplicates()

calidad(ventas_limpio, "Ventas Limpio", clave="id_venta")

df_ventas.value_counts(subset=["id_venta","producto","precio","cantidad"], dropna=False).sort_values(ascending=False)

def normalizar_texto(df):
    for col in df.select_dtypes(include="object").columns:
        df[col] = (
            df[col]
            .astype(str)                      # A texto
            .str.strip()                      # Quita espacios al inicio y final
            .str.replace(r"[\u200b\t\r\n]", "", regex=True)  # Elimina caracteres invisibles
            .str.replace(" +", " ", regex=True)               # Reduce espacios m√∫ltiples
            .str.title()                      # Formato t√≠tulo ("juan p√©rez" ‚Üí "Juan P√©rez")
        )
    return df

# Normalizar columnas de fechas
for df in [ventas_limpio, clientes_limpio, marketing_limpio]:
    for col in df.columns:
        if "fecha" in col.lower():  # Busca columnas que contengan "fecha"
            df[col] = pd.to_datetime(df[col], errors="coerce", dayfirst=True)
            # Convierte a datetime; valores inv√°lidos ‚Üí NaT; formato d√≠a/mes/a√±o

#Normalizar fechas de df marketing

marketing_limpio["fecha_inicio"] = pd.to_datetime(marketing_limpio["fecha_inicio"], errors="coerce", dayfirst=True)
marketing_limpio["fecha_fin"] = pd.to_datetime(marketing_limpio["fecha_fin"], errors="coerce", dayfirst=True)

print(ventas_limpio.dtypes)
print(clientes_limpio.dtypes)
print(marketing_limpio.dtypes)

#Aplicar la normalizaci√≥n de texto

ventas_limpio = normalizar_texto(ventas_limpio)
clientes_limpio = normalizar_texto(clientes_limpio)
marketing_limpio = normalizar_texto(marketing_limpio)

#Mostrar los df luego de normalizar los textos para revisar que queden bien
print(ventas_limpio.head(10))
print(clientes_limpio.head(10))
print(marketing_limpio.head(10))

# Normalizar valores num√©ricos
if "precio" in ventas_limpio.columns:
    ventas_limpio["precio"] = (
        ventas_limpio["precio"]
        .astype(str)                      # A texto
        .str.replace("$", "", regex=False)  # Quita s√≠mbolo $
        .str.replace(",", "", regex=False)  # Quita comas de miles
        .str.strip()                      # Elimina espacios
    )
    ventas_limpio["precio"] = pd.to_numeric(ventas_limpio["precio"], errors="coerce")  # Convierte a n√∫mero, inv√°lidos ‚Üí NaN

print(ventas_limpio.dtypes, "\n")

print(ventas_limpio.columns)

# Normalizar columna "cantidad". Convierte la columna a enteros permitiendo valores nulos.
if "cantidad" in ventas_limpio.columns:
    ventas_limpio["cantidad"] = pd.to_numeric(ventas_limpio["cantidad"], errors="coerce").astype("Int64")

print(ventas_limpio.dtypes)

#Guardar DataFrames limpios como CSV
ventas_limpio.info()  # Informaci√≥n r√°pida del DataFrame

ventas_limpio.to_csv("/content/drive/MyDrive/datasets/ventas_limpio.csv", index=False)
clientes_limpio.to_csv("/content/drive/MyDrive/datasets/clientes_limpio.csv", index=False)
marketing_limpio.to_csv("/content/drive/MyDrive/datasets/marketing_limpio.csv", index=False)

print("Archivos guardados: ventas_limpio.csv, clientes_limpio.csv, marketing_limpio.csv")

# ============================================
# 7) TRANSFORMACI√ìN: productos de alto rendimiento
# ============================================
# Objetivo:
# - Detectar los productos con mejor desempe√±o econ√≥mico (top 20% por ingreso total).
# - Aplicar transformaci√≥n: calcular ingreso, agregar por producto y filtrar.
# ============================================

def encontrar_columna(df, candidatos):
    """
    Busca la primera columna cuyo nombre contenga alguno de los patrones dados.
    - df: DataFrame de pandas.
    - candidatos: lista de patrones (min√∫sculas).
    """
    # Recorremos todas las columnas del DataFrame
    for c in df.columns:

        # Convertimos el nombre de la columna a min√∫sculas
        # Esto se hace para comparar sin importar si est√° escrito con may√∫sculas o min√∫sculas
        nombre = c.lower()

        # Verificamos si alguna palabra (patr√≥n) de la lista 'candidatos'
        # est√° contenida dentro del nombre de la columna
        # 'any()' devuelve True apenas encuentra una coincidencia
        if any(p in nombre for p in candidatos):
            # Si encontramos una coincidencia, devolvemos el nombre original de la columna
            return c

    # Si termina el bucle y no se encontr√≥ ninguna coincidencia, devolvemos None
    return None


# Detectar la columna de producto
prod_col = encontrar_columna(ventas_limpio, ["producto", "id_producto", "sku", "articulo", "art√≠culo"])
if prod_col is None:
    raise ValueError("No se encontr√≥ columna de producto. Renombr√° una columna a 'producto' o similar.")
print(prod_col)



# Calcular ingreso por registro = precio * cantidad
# assign: crea nuevas columnas y devuelve una copia del DF
ventas_perf = (
    ventas_limpio
    .assign(
        ingreso = ventas_limpio["precio"] * ventas_limpio["cantidad"]
       ))


# Agregar m√©tricas por producto
resumen_prod = (
    ventas_perf
    # 1) Agrupamos el DataFrame por una o varias columnas clave
    .groupby(
        by=prod_col,
        dropna=False,
        as_index=False,
        observed=False
            )
    # 2) Agregamos columnas num√©ricas por cada grupo
    .agg(
        ingreso_total=('ingreso', 'sum'),
        unidades=('cantidad', 'sum'),
        precio_promedio=('precio', 'mean'),
        registros=('ingreso', 'size')
    ))

#Ordenar resumen_prod por el mayor ingreso_total, y redondear precio_promedio a 2 decimales redondeado
print(resumen_prod.head(10))

# ============================================
# 4Calcular percentil 80 de ingreso_total
# ============================================
p80_ingreso = resumen_prod["ingreso_total"].quantile(q=0.80, interpolation="linear")

# ============================================
# Filtrar y ordenar productos de alto rendimiento
# ============================================
ventas_top = (
    resumen_prod
    .query("ingreso_total >= @p80_ingreso", engine="python")
    .sort_values(
        by=["ingreso_total", "unidades"],
        ascending=[False, False],
        na_position="last",
        ignore_index=True
    )
)

# ============================================
# Mostrar resultados
# ============================================
print(f"Columna de producto detectada: {prod_col}")
print(f"Umbral (P80) de ingreso_total: {float(p80_ingreso):,.2f}")
print("‚úÖ Productos de ALTO RENDIMIENTO (top 20% por ingreso):")
display(ventas_top.head(20))

# ============================================
# 8) Agregaci√≥n: resumen las ventas por categor√≠a
# ============================================

def encontrar_columna(df, candidatos):
    """Devuelve la primera columna cuyo nombre contenga alguno de los patrones dados (insensible a may√∫sculas)."""
    for c in df.columns:
        if any(p in c.lower() for p in candidatos):
            return c
    return None

# 1) Detectar columna de categor√≠a
cat_col = encontrar_columna(ventas_limpio, ["categoria", "categor√≠a", "categoria_producto", "rubro"])
if cat_col is None:
    raise ValueError("No se encontr√≥ columna de categor√≠a (por ej. 'categoria' o 'rubro').")

# 2) Crear columna 'ingreso' si no existe
ventas_cat = (
    ventas_limpio.assign(ingreso=ventas_limpio["precio"] * ventas_limpio["cantidad"])
    if "ingreso" not in ventas_limpio.columns else ventas_limpio.copy()
)

# 3) Agregaci√≥n por categor√≠a
resumen_cat = (
    ventas_cat
    .groupby(cat_col, dropna=False, as_index=False)
    .agg(
        ingreso_total=('ingreso', 'sum'),
        unidades=('cantidad', 'sum'),
        ventas=('ingreso', 'size'),
        precio_promedio=('precio', 'mean')
    )
    .sort_values('ingreso_total', ascending=False, na_position='last', ignore_index=True)
)

# 4) Ticket promedio por venta
resumen_cat["ticket_promedio_por_venta"] = resumen_cat["ingreso_total"] / resumen_cat["ventas"]

# 5) Mostrar resultados
print("Columna de categor√≠a detectada:", cat_col)
print("Resumen por categor√≠a (ordenado por ingreso_total):")
display(resumen_cat.head(20))

# Integraci√≥n de ventas y marketing

# 1) Buscar clave com√∫n para unir (por nombre t√≠pico o manual)
claves_tentativas = ["producto", "id", "nombre"] # Added potential column names
clave_comun = None
clave_ventas = None
clave_marketing = None

# Find a common key based on tentative names
for tentative_key in claves_tentativas:
    if tentative_key in ventas_limpio.columns and tentative_key in marketing_limpio.columns:
        clave_comun = tentative_key
        break

# If no common key found by name, try specific column names
if clave_comun is None:
    # You can manually set these if the automatic detection fails
    # clave_ventas = "nombre_columna_ventas"
    # clave_marketing = "nombre_columna_marketing"
    pass # Keep manual keys as None for now if not set

# Si no hay clave com√∫n ni manual, mostrar gu√≠a y salir
if clave_comun is None and (clave_ventas is None or clave_marketing is None):
    print("‚ùå No se encontr√≥ una clave com√∫n por nombre.")
    print("üëâ Defin√≠ 'clave_ventas' y 'clave_marketing' o renombr√° columnas.")
else:
    # 2) Definir columnas de uni√≥n y detectar cardinalidad
    if clave_comun:
        left_on = right_on = [clave_comun]
    else:
        left_on = [clave_ventas]
        right_on = [clave_marketing]

    def hay_duplicados(df, cols):
        return df.duplicated(subset=cols, keep=False).any()

    # Changed dataframe names to the cleaned versions
    dup_left = hay_duplicados(ventas_limpio, left_on)
    dup_right = hay_duplicados(marketing_limpio, right_on)

    validate_card = (
        "1:1" if not dup_left and not dup_right else
        "1:m" if not dup_left and dup_right else
        "m:1" if dup_left and not dup_right else
        "m:m"
    )

    # 3) Merge con how='left' y validaci√≥n de cardinalidad
    # Changed dataframe names to the cleaned versions
    ventas_marketing = pd.merge(
        ventas_limpio, marketing_limpio,
        how="left",
        left_on=left_on, right_on=right_on,
        suffixes=("_ven", "_mkt"),
        indicator=True,
        validate=validate_card # Added validation
    )

    # 4) Diagn√≥stico del merge
    display(ventas_marketing['_merge'].value_counts(dropna=False).to_frame('conteo'))
    display(ventas_marketing.head())

    # 5) Resumen por campa√±a y canal (si existen)
    vm = ventas_marketing.copy()
    if "ingreso" not in vm.columns and {"precio", "cantidad"}.issubset(vm.columns):
        vm["ingreso"] = vm["precio"] * vm["cantidad"]

    def hallar_col(df, patrones):
        return next((c for c in df.columns if any(p in c.lower() for p in patrones)), None)

    camp_col = hallar_col(vm, ["campa√±a", "campana", "campaign", "id_campanha"]) # Added id_campanha
    canal_col = hallar_col(vm, ["canal", "utm_source", "fuente", "source"])

    if camp_col and "ingreso" in vm.columns:
        resumen_camp = vm.groupby(camp_col, dropna=False).agg(
            ingreso_total=('ingreso', 'sum'),
            ventas=('ingreso', 'size')
        ).sort_values('ingreso_total', ascending=False)
        display(resumen_camp.head(20))

    if canal_col and "ingreso" in vm.columns:
        resumen_canal = vm.groupby(canal_col, dropna=False).agg(
            ingreso_total=('ingreso', 'sum'),
            ventas=('ingreso', 'size')
        ).sort_values('ingreso_total', ascending=False)
        display(resumen_canal.head(20))
